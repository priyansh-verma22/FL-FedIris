{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19304de0-5fac-4255-a02e-7bbd80be78aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score, f1_score, recall_score\n",
    "import seaborn as sns\n",
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "613647ec-0776-4d20-902a-5357017b69e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model_path, test_dir, target_size=(224, 224), output_dir=r\"C:\\Users\\priya\\Desktop\\Iris_Recognition\\Gpt\\Evaluation_Result\"):\n",
    "    \"\"\"\n",
    "    Evaluate a trained model on test data with comprehensive metrics and visualizations.\n",
    "    Includes detailed debugging for confusion matrix issues.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create output directory\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "\n",
    "        # Load model\n",
    "        try:\n",
    "            model = load_model(model_path)\n",
    "            print(\"Model loaded successfully\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model: {str(e)}\")\n",
    "            return\n",
    "\n",
    "        # Create test data generator with consistent target size\n",
    "        test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "        test_generator = test_datagen.flow_from_directory(\n",
    "            test_dir,\n",
    "            target_size=target_size,\n",
    "            batch_size=16,\n",
    "            class_mode='categorical',\n",
    "            shuffle=False\n",
    "        )\n",
    "        print(f\"Found {test_generator.samples} images belonging to {len(test_generator.class_indices)} classes.\")\n",
    "\n",
    "        # Create index-to-class mapping\n",
    "        class_indices = test_generator.class_indices\n",
    "        index_to_class = {v: k for k, v in class_indices.items()}\n",
    "        class_labels = list(class_indices.keys())\n",
    "        print(f\"Class indices: {class_indices}\")\n",
    "\n",
    "        # Evaluate model to get a baseline\n",
    "        test_loss, test_acc = model.evaluate(test_generator, verbose=2)\n",
    "        print(f\"\\nTest accuracy: {test_acc:.4f}\")\n",
    "        print(f\"Test loss: {test_loss:.4f}\")\n",
    "\n",
    "        # Make predictions with explicit steps\n",
    "        test_generator.reset()\n",
    "        num_samples = test_generator.samples\n",
    "        predictions = model.predict(test_generator, steps=int(num_samples / test_generator.batch_size), verbose=1)\n",
    "        predicted_classes = np.argmax(predictions[:num_samples], axis=1)  # Ensure length matches\n",
    "        true_classes = test_generator.classes[:num_samples]\n",
    "\n",
    "        # Debugging prints\n",
    "        print(f\"Number of true classes: {len(true_classes)}\")\n",
    "        print(f\"Number of predicted classes: {len(predicted_classes)}\")\n",
    "        print(f\"Sample predictions: {predicted_classes[:10]}\")\n",
    "        print(f\"Sample true classes: {true_classes[:10]}\")\n",
    "        print(f\"Max prediction value: {np.max(predictions)}\")\n",
    "        print(f\"Min prediction value: {np.min(predictions)}\")\n",
    "\n",
    "        # Verify and adjust lengths\n",
    "        if len(true_classes) != len(predicted_classes):\n",
    "            print(f\"Warning: Mismatch in lengths - True: {len(true_classes)}, Predicted: {len(predicted_classes)}\")\n",
    "            min_length = min(len(true_classes), len(predicted_classes))\n",
    "            true_classes = true_classes[:min_length]\n",
    "            predicted_classes = predicted_classes[:min_length]\n",
    "        else:\n",
    "            print(\"Lengths match successfully\")\n",
    "\n",
    "        # Calculate confusion matrix\n",
    "        cm = confusion_matrix(true_classes, predicted_classes)\n",
    "        print(f\"Confusion matrix shape: {cm.shape}\")\n",
    "        print(f\"Confusion matrix content:\\n{cm}\")\n",
    "\n",
    "        # Plot full confusion matrix for first 10 classes\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        sns.heatmap(cm[:10, :10], annot=True, fmt='d', cmap='Blues',  # Limit to 10x10 for readability\n",
    "                    xticklabels=class_labels[:10],\n",
    "                    yticklabels=class_labels[:10])\n",
    "        plt.title('Confusion Matrix (First 10 Classes)')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.savefig(os.path.join(output_dir, 'confusion_matrix.png'))\n",
    "        plt.close()\n",
    "\n",
    "        macro_precision = precision_score(true_classes, predicted_classes, average=\"macro\", zero_division=0)  \n",
    "        macro_recall    = recall_score   (true_classes, predicted_classes, average=\"macro\", zero_division=0)  \n",
    "        macro_f1        = f1_score       (true_classes, predicted_classes, average=\"macro\", zero_division=0) \n",
    "\n",
    "        # Calculate and save classification report\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(true_classes, predicted_classes, target_names=class_labels, zero_division=0))\n",
    "        with open(os.path.join(output_dir, 'classification_report.txt'), 'w') as f:\n",
    "            f.write(classification_report(true_classes, predicted_classes, target_names=class_labels, zero_division=0))\n",
    "\n",
    "        # Save overall metrics\n",
    "        accuracy = np.mean(predicted_classes == true_classes)\n",
    "        metrics = {\n",
    "            'test_accuracy': test_acc,\n",
    "            'test_loss': test_loss,\n",
    "            'overall_accuracy': accuracy,\n",
    "            'timestamp': datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        }\n",
    "        with open(os.path.join(output_dir, 'metrics.txt'), 'w') as f:\n",
    "            for key, value in metrics.items():\n",
    "                f.write(f\"{key}: {value}\\n\")\n",
    "\n",
    "        print(f\"\\nOverall Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Evaluation results saved in {output_dir}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73abdab6-c7f4-41ae-8d2e-b7f76fd8e930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\priya\\.conda\\envs\\Iris_Reco\\Lib\\site-packages\\h5py\\tests\\data_files\\vlen_string_dset.h5\n",
      "C:\\Users\\priya\\.conda\\envs\\Iris_Reco\\Lib\\site-packages\\h5py\\tests\\data_files\\vlen_string_dset_utc.h5\n",
      "C:\\Users\\priya\\.conda\\envs\\Iris_Reco\\Lib\\site-packages\\h5py\\tests\\data_files\\vlen_string_s390x.h5\n",
      "C:\\Users\\priya\\.conda\\pkgs\\h5py-3.12.1-py39h535c9fb_1\\Lib\\site-packages\\h5py\\tests\\data_files\\vlen_string_dset.h5\n",
      "C:\\Users\\priya\\.conda\\pkgs\\h5py-3.12.1-py39h535c9fb_1\\Lib\\site-packages\\h5py\\tests\\data_files\\vlen_string_dset_utc.h5\n",
      "C:\\Users\\priya\\.conda\\pkgs\\h5py-3.12.1-py39h535c9fb_1\\Lib\\site-packages\\h5py\\tests\\data_files\\vlen_string_s390x.h5\n",
      "C:\\Users\\priya\\.keras\\models\\resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "C:\\Users\\priya\\AppData\\Roaming\\Python\\Python38\\site-packages\\h5py\\tests\\data_files\\vlen_string_dset.h5\n",
      "C:\\Users\\priya\\AppData\\Roaming\\Python\\Python38\\site-packages\\h5py\\tests\\data_files\\vlen_string_dset_utc.h5\n",
      "C:\\Users\\priya\\AppData\\Roaming\\Python\\Python38\\site-packages\\h5py\\tests\\data_files\\vlen_string_s390x.h5\n",
      "C:\\Users\\priya\\Desktop\\Iris_Recognition\\Gpt\\results\\global_model_final.h5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "for root, dirs, files in os.walk(\"C:\\\\Users\\\\priya\"):\n",
    "    for file in files:\n",
    "        if file.endswith(\".h5\"):\n",
    "            print(os.path.join(root, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95a22a55-9ef9-4ddc-8fa5-79c1c3a1a5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Evaluating model on Client1_Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully\n",
      "Found 148 images belonging to 74 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\priya\\.conda\\envs\\Iris_Reco\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 148 images belonging to 74 classes.\n",
      "Class indices: {'001': 0, '002': 1, '003': 2, '004': 3, '005': 4, '006': 5, '007': 6, '008': 7, '009': 8, '010': 9, '011': 10, '012': 11, '013': 12, '014': 13, '015': 14, '016': 15, '017': 16, '018': 17, '019': 18, '020': 19, '021': 20, '022': 21, '023': 22, '024': 23, '025': 24, '026': 25, '027': 26, '028': 27, '029': 28, '030': 29, '031': 30, '032': 31, '033': 32, '034': 33, '035': 34, '036': 35, '037': 36, '038': 37, '039': 38, '040': 39, '041': 40, '042': 41, '043': 42, '044': 43, '045': 44, '046': 45, '047': 46, '048': 47, '049': 48, '050': 49, '051': 50, '052': 51, '053': 52, '054': 53, '055': 54, '056': 55, '057': 56, '058': 57, '059': 58, '060': 59, '061': 60, '062': 61, '063': 62, '064': 63, '065': 64, '066': 65, '067': 66, '068': 67, '069': 68, '070': 69, '071': 70, '072': 71, '073': 72, '074': 73}\n",
      "10/10 - 7s - 656ms/step - accuracy: 0.9122 - loss: 0.8292\n",
      "\n",
      "Test accuracy: 0.9122\n",
      "Test loss: 0.8292\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 525ms/step\n",
      "Number of true classes: 148\n",
      "Number of predicted classes: 144\n",
      "Sample predictions: [41  0  1  1  2  2  3  3  4  4]\n",
      "Sample true classes: [0 0 1 1 2 2 3 3 4 4]\n",
      "Max prediction value: 0.9524366855621338\n",
      "Min prediction value: 1.8677203783568075e-08\n",
      "Warning: Mismatch in lengths - True: 148, Predicted: 144\n",
      "Confusion matrix shape: (72, 72)\n",
      "Confusion matrix content:\n",
      "[[1 0 0 ... 0 0 0]\n",
      " [0 2 0 ... 0 0 0]\n",
      " [0 0 2 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 2 0 0]\n",
      " [0 0 0 ... 0 2 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "\n",
      "Classification Report:\n",
      "An unexpected error occurred: Number of classes, 72, does not match size of target_names, 74. Try specifying the labels parameter\n",
      "\n",
      "üîç Evaluating model on Client2_Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully\n",
      "Found 148 images belonging to 74 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\priya\\.conda\\envs\\Iris_Reco\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 148 images belonging to 74 classes.\n",
      "Class indices: {'075': 0, '076': 1, '077': 2, '078': 3, '079': 4, '080': 5, '081': 6, '082': 7, '083': 8, '084': 9, '085': 10, '086': 11, '087': 12, '088': 13, '089': 14, '090': 15, '091': 16, '092': 17, '093': 18, '094': 19, '095': 20, '096': 21, '097': 22, '098': 23, '099': 24, '100': 25, '101': 26, '102': 27, '103': 28, '104': 29, '105': 30, '106': 31, '107': 32, '108': 33, '109': 34, '110': 35, '111': 36, '112': 37, '113': 38, '114': 39, '115': 40, '116': 41, '117': 42, '118': 43, '119': 44, '120': 45, '121': 46, '122': 47, '123': 48, '124': 49, '125': 50, '126': 51, '127': 52, '128': 53, '129': 54, '130': 55, '131': 56, '132': 57, '133': 58, '134': 59, '135': 60, '136': 61, '137': 62, '138': 63, '139': 64, '140': 65, '141': 66, '142': 67, '143': 68, '144': 69, '145': 70, '146': 71, '147': 72, '148': 73}\n",
      "10/10 - 6s - 641ms/step - accuracy: 0.8446 - loss: 1.1350\n",
      "\n",
      "Test accuracy: 0.8446\n",
      "Test loss: 1.1350\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 491ms/step\n",
      "Number of true classes: 148\n",
      "Number of predicted classes: 144\n",
      "Sample predictions: [0 0 1 1 2 2 3 3 4 4]\n",
      "Sample true classes: [0 0 1 1 2 2 3 3 4 4]\n",
      "Max prediction value: 0.975862979888916\n",
      "Min prediction value: 1.8104387322637194e-07\n",
      "Warning: Mismatch in lengths - True: 148, Predicted: 144\n",
      "Confusion matrix shape: (73, 73)\n",
      "Confusion matrix content:\n",
      "[[2 0 0 ... 0 0 0]\n",
      " [0 2 0 ... 0 0 0]\n",
      " [0 0 2 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 2 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "\n",
      "Classification Report:\n",
      "An unexpected error occurred: Number of classes, 73, does not match size of target_names, 74. Try specifying the labels parameter\n",
      "\n",
      "üîç Evaluating model on Client3_Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully\n",
      "Found 146 images belonging to 74 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\priya\\.conda\\envs\\Iris_Reco\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 146 images belonging to 74 classes.\n",
      "Class indices: {'.ipynb_checkpoints': 0, '149': 1, '150': 2, '151': 3, '152': 4, '153': 5, '154': 6, '155': 7, '156': 8, '157': 9, '158': 10, '159': 11, '160': 12, '161': 13, '162': 14, '163': 15, '164': 16, '165': 17, '166': 18, '167': 19, '168': 20, '169': 21, '170': 22, '171': 23, '172': 24, '173': 25, '174': 26, '175': 27, '176': 28, '177': 29, '178': 30, '179': 31, '180': 32, '181': 33, '182': 34, '183': 35, '184': 36, '185': 37, '186': 38, '187': 39, '188': 40, '189': 41, '190': 42, '191': 43, '192': 44, '193': 45, '194': 46, '195': 47, '196': 48, '197': 49, '198': 50, '199': 51, '200': 52, '201': 53, '202': 54, '203': 55, '204': 56, '205': 57, '206': 58, '207': 59, '208': 60, '209': 61, '210': 62, '211': 63, '212': 64, '213': 65, '214': 66, '215': 67, '216': 68, '217': 69, '218': 70, '219': 71, '220': 72, '221': 73}\n",
      "10/10 - 6s - 627ms/step - accuracy: 0.8630 - loss: 1.0845\n",
      "\n",
      "Test accuracy: 0.8630\n",
      "Test loss: 1.0845\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 482ms/step\n",
      "Number of true classes: 146\n",
      "Number of predicted classes: 144\n",
      "Sample predictions: [1 1 2 2 3 3 4 4 5 5]\n",
      "Sample true classes: [1 1 2 2 3 3 4 4 5 5]\n",
      "Max prediction value: 0.9170053601264954\n",
      "Min prediction value: 8.487887157571095e-07\n",
      "Warning: Mismatch in lengths - True: 146, Predicted: 144\n",
      "Confusion matrix shape: (73, 73)\n",
      "Confusion matrix content:\n",
      "[[2 0 0 ... 0 0 0]\n",
      " [0 2 0 ... 0 0 0]\n",
      " [0 0 2 ... 0 0 0]\n",
      " ...\n",
      " [0 1 0 ... 1 0 0]\n",
      " [0 0 0 ... 0 2 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "\n",
      "Classification Report:\n",
      "An unexpected error occurred: Number of classes, 73, does not match size of target_names, 74. Try specifying the labels parameter\n"
     ]
    }
   ],
   "source": [
    "  model_path = r\"C:\\Users\\priya\\Desktop\\Iris_Recognition\\Gpt\\results\\global_model_final.h5\"\n",
    "\n",
    "test_dirs = {\n",
    "    \"Client1_Test\": r\"C:\\Users\\priya\\Desktop\\Iris_Recognition\\Final_Dataset\\Clients\\client1\\test\",\n",
    "    \"Client2_Test\": r\"C:\\Users\\priya\\Desktop\\Iris_Recognition\\Final_Dataset\\Clients\\client2\\test\",\n",
    "    \"Client3_Test\": r\"C:\\Users\\priya\\Desktop\\Iris_Recognition\\Final_Dataset\\Clients\\client3\\test\"\n",
    "}\n",
    "\n",
    "for client_name, path in test_dirs.items():\n",
    "    print(f\"\\nüîç Evaluating model on {client_name}...\")\n",
    "    evaluate_model(model_path, path, target_size=(224, 224))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7624da-ad45-4ff4-8286-01e26c8939d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ee1d1f-863e-4836-933c-1d655ee318d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fda126a-01b2-4b53-a10e-9aae4fb70c26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e4ead1-4dd4-439e-9d96-4de51fe7af39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
